{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d44dc11-d9d1-4972-adc6-b4326c773062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taejunsong/workspace/rag_tutorial/.env\n"
     ]
    }
   ],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "import urllib.parse\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "root_dir = Path().resolve()\n",
    "print(root_dir.parent/'.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59b24031-b7c0-4aef-ab97-160bc7ca9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(RepositoryEnv(root_dir.parent/'.env'))  # Explicitly load .env\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config('LANGSMITH_API_KEY')\n",
    "# os.environ[\"GROQ_API_KEY\"] = config(\"GROQ_API_KEY\")\n",
    "# llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n",
    "llm = ChatOllama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb7d12cc-2e8c-49f2-b71f-62d3b453997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fcbfed5-e240-40f1-bd6d-a751e619bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change this into LLM\n",
    "def build_search_url(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Build the search URL from a user query.\n",
    "    Note: This URL structure is hypothetical. You’ll need to adjust the base URL\n",
    "    and query parameters based on how apartment.com constructs its search URLs.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.apartment.com/search\"  # Adjust as necessary\n",
    "    params = {\"q\": query}\n",
    "    search_url = f\"{base_url}?{urllib.parse.urlencode(params)}\"\n",
    "    return search_url\n",
    "    \n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    \"\"\"\n",
    "    A custom web loader that fetches a webpage with custom headers and retry logic,\n",
    "    then filters the HTML to only include the <section> tag with the specified attributes.\n",
    "    The filtered HTML is returned as a LangChain Document object.\n",
    "    \"\"\"\n",
    "    def load(self):\n",
    "        # Define custom headers to mimic a browser.\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "        }\n",
    "        # Create a session with retry logic.\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()  # Check for HTTP errors.\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        \n",
    "        # Use SoupStrainer to filter only the desired <section> tag.\n",
    "        # filter_section = SoupStrainer(\"section\", attrs={\n",
    "        #     \"class\": \"placards placardsv2\",\n",
    "        #     \"id\": \"placards\",\n",
    "        #     \"data-nosnippet\": \"\"\n",
    "        # })\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\", \n",
    "            id=\"placardContainer\", \n",
    "            class_=\"placardContainer\", \n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        content = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section).get_text(separator=\"\\n\", strip=True)\n",
    "        doc = Document(page_content=content, metadata={\"source\": self.web_path})\n",
    "        return [doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35817bf-3e66-4cf0-b93c-d18b75ea4269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.apartment.com/search?q=2+bedroom+apartments+in+Los+Angeles'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4df7e1e-2d50-47c5-b7b6-2a7d1852faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "user_query = \"2 bedroom apartments in Los Angeles\"\n",
    "target_url = build_search_url(user_query)\n",
    "loader = CustomWebLoader(target_url)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0258ca2-f55b-4f16-b8d8-6c18cda84ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.apartment.com/search?q=2+bedroom+apartments+in+Los+Angeles'}, page_content='Apartments for Rent in Chicago IL - 23,204 Rentals\\nPresidential Towers\\n555 W Madison St, Chicago, IL 60661\\n1\\n/\\n72\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,400 - $9,400\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nGrill\\nCourtyard\\n(708) 725-1991\\nEmail\\nSentral Michigan Avenue\\n808 S Michigan Ave, Chicago, IL 60605\\n1\\n/\\n31\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,116 - $11,500\\nStudio - 4 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nIn Unit Washer & Dryer\\nStainless Steel Appliances\\n(708) 797-6742\\nEmail\\nThe 808 Cleveland\\n808 N Cleveland Ave, Chicago, IL 60610\\n1\\n/\\n155\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,185 - $5,068\\nStudio - 4 Beds\\nPets Allowed\\nFitness Center\\nPool\\nIn Unit Washer & Dryer\\nStainless Steel Appliances\\nBusiness Center\\nPackage Service\\n(708) 934-9407\\nEmail\\nPost\\n853 W Blackhawk St, Chicago, IL 60642\\n1\\n/\\n130\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,284 - $3,799\\nStudio - 4 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nIn Unit Washer & Dryer\\nControlled Access\\nEV Charging\\nFurnished\\n(224) 935-9769\\nEmail\\n180 North Jefferson\\n180 N Jefferson St, Chicago, IL 60661\\n1\\n/\\n56\\n3D Tours\\nVirtual Tour\\n$2,104 - $3,842\\nStudio - 3 Beds\\nFitness Center\\nDishwasher\\nIn Unit Washer & Dryer\\nWalk-In Closets\\nBusiness Center\\nPackage Service\\nGranite Countertops\\n(708) 303-6736\\nEmail\\nShoreham and Tides\\n400 E South Water St, Chicago, IL 60601\\n1\\n/\\n58\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,334 - $6,710\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nPool\\nHigh-Speed Internet\\nConcierge\\n(708) 775-3187\\nEmail\\nThe Residences at NewCity\\n1457 N Halsted St, Chicago, IL 60642\\n1\\n/\\n72\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,699 - $5,265\\nStudio - 2 Beds\\n1 Month Free\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nRefrigerator\\nKitchen\\n(708) 919-2291\\nEmail\\nMILA\\n201 N Garland Ct, Chicago, IL 60601\\n1\\n/\\n74\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,173 - $5,574\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nPool\\nPackage Service\\n(833) 787-0144\\nEmail\\nAMLI 808\\n808 N Wells St, Chicago, IL 60610\\n1\\n/\\n37\\n3D Tours\\nVirtual Tour\\n$2,021 - $5,309\\nStudio - 2 Beds\\nPets Allowed\\nPool\\nDishwasher\\nRefrigerator\\nKitchen\\nIn Unit Washer & Dryer\\n(708) 919-3074\\nEmail\\nCascade\\n455 E Waterside Dr, Chicago, IL 60601\\n1\\n/\\n51\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,596 - $8,141\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nPool\\nBalcony\\nMaintenance on site\\nGrill\\nPackage Service\\n(312) 757-8219\\nEmail\\nMcCormick\\n2401 S State St, Chicago, IL 60616\\n1\\n/\\n34\\n$996 - $1,408\\n4 Beds\\nFitness Center\\nIn Unit Washer & Dryer\\nControlled Access\\nRooftop Deck\\nFurnished\\n(872) 253-7718\\nEmail\\nInspire West Town\\n670 N May St, Chicago, IL 60642\\n1\\n/\\n87\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,130 - $4,200\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nIn Unit Washer & Dryer\\nDisposal\\nStainless Steel Appliances\\nControlled Access\\n(312) 997-5068\\nEmail\\nMillie on Michigan\\n88 E Wacker Pl, Chicago, IL 60601\\n1\\n/\\n98\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,555 - $8,424\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nPool\\nIn Unit Washer & Dryer\\nMaintenance on site\\nSmoke Free\\n(312) 870-5520\\nEmail\\nThe Teller House\\n4753 N Broadway St, Chicago, IL 60640\\n1\\n/\\n28\\n3D Tours\\nVirtual Tour\\n$1,177 - $1,985\\nStudio - 1 Bed\\nSpecials\\nPets Allowed\\nFitness Center\\nKitchen\\nMaintenance on site\\nPatio\\nElevator\\n(224) 529-0625\\nEmail\\nThe Sally\\n1135 W Winona St, Chicago, IL 60640\\n1\\n/\\n60\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,595 - $4,600\\nStudio - 3 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nKitchen\\nIn Unit Washer & Dryer\\n(224) 260-2483\\nEmail\\nFlora\\n1114 W Carroll Ave, Chicago, IL 60607\\n1\\n/\\n47\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,206 - $16,705\\nStudio - 3 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nIn Unit Washer & Dryer\\nGated\\nRooftop Deck\\n(877) 865-0747\\nEmail\\nPark Michigan - 1212 S Michigan Ave\\n1212 S Michigan Ave, Chicago, IL 60605\\n1\\n/\\n64\\n3D Tours\\nVirtual Tour\\n$1,749 - $3,272\\nStudio - 2 Beds\\n1 Month Free\\nPets Allowed\\nFitness Center\\nDishwasher\\nHigh-Speed Internet\\nGrill\\nElevator\\nRooftop Deck\\n(708) 919-2811\\nEmail\\nMDA Apartments\\n63 E Lake St, Chicago, IL 60601\\n1\\n/\\n105\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,750 - $2,990\\nStudio - 2 Beds\\n2 Months Free\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nKitchen\\nIn Unit Washer & Dryer\\n(312) 685-4373\\nEmail\\nArrive Streeterville\\n333 E Ontario St, Chicago, IL 60611\\n1\\n/\\n42\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,815 - $6,340\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nRefrigerator\\nWalk-In Closets\\n(708) 919-2992\\nEmail\\nCoast at Lakeshore East\\n345 E Wacker Dr, Chicago, IL 60601\\n1\\n/\\n65\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,000 - $10,446\\nStudio - 3 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nRefrigerator\\nKitchen\\n(708) 434-2554\\nEmail\\nExhibit on Superior\\n165 W Superior St, Chicago, IL 60654\\n1\\n/\\n130\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,232 - $10,552\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nPool\\nIn Unit Washer & Dryer\\nMaintenance on site\\nHigh-Speed Internet\\nBusiness Center\\n(708) 401-9108\\nEmail\\nNorth Harbor Tower\\n175 N Harbor Dr, Chicago, IL 60601\\n1\\n/\\n37\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,875 - $7,835\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nPool\\nCourtyard\\nDoorman\\n(708) 775-3334\\nEmail\\nThe Chicagoan\\n750 N RUSH St, CHICAGO, IL 60611\\n1\\n/\\n74\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,327 - $3,842\\n1-2 Beds\\nDiscounts\\nCats Allowed\\nFitness Center\\nPool\\nIn Unit Washer & Dryer\\nBusiness Center\\nGranite Countertops\\nSmoke Free\\n(708) 797-9767\\nEmail\\n1001 South State\\n1001 S State St, Chicago, IL 60605\\n1\\n/\\n39\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,011 - $9,258\\nStudio - 3 Beds\\n1 Month Free\\nPets Allowed\\nFitness Center\\nPool\\nRefrigerator\\nKitchen\\nIn Unit Washer & Dryer\\n(708) 298-5546\\nEmail\\nWest77 Apartments\\n77 W Huron, Chicago, IL 60654\\n1\\n/\\n52\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,030 - $4,806\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nKitchen\\nIn Unit Washer & Dryer\\nBalcony\\n(708) 775-2543\\nEmail\\nSoNu Digs\\n1515 N Fremont St, Chicago, IL 60642\\n1\\n/\\n65\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,445 - $1,725\\nStudio\\nPets Allowed\\nIn Unit Washer & Dryer\\nHeat\\nControlled Access\\n(708) 725-1662\\nEmail\\nWolf Point East\\n313 W Wolf Point Plz, Chicago, IL 60654\\n1\\n/\\n32\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,460 - $16,521\\nStudio - 3 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nClubhouse\\nGrill\\nLounge\\nConcierge\\n(312) 764-1281\\nEmail\\nLawrence Lofts\\n1049 W Lawrence Ave, Chicago, IL 60640\\n1\\n/\\n41\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,500 - $3,245\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nDishwasher\\nIn Unit Washer & Dryer\\nHigh-Speed Internet\\nElevator\\nRooftop Deck\\n(224) 435-5243\\nEmail\\nStraits Row\\n633 S La Salle St, Chicago, IL 60605\\n1\\n/\\n11\\n$1,699 - $2,399\\nStudio - 4 Beds\\nPets Allowed\\nFitness Center\\nPool\\nIn Unit Washer & Dryer\\nWalk-In Closets\\nHigh-Speed Internet\\nFurnished\\n(872) 253-7991\\nEmail\\nOne Superior Place\\n1 W Superior St, Chicago, IL 60654\\n1\\n/\\n60\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,039 - $4,015\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nRefrigerator\\nKitchen\\n(708) 919-3364\\nEmail\\nAMLI Lofts\\n850 S Clark St, Chicago, IL 60605\\n1\\n/\\n37\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,152 - $4,911\\nStudio - 2 Beds\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nIn Unit Washer & Dryer\\nEV Charging\\nRooftop Deck\\n(609) 916-1265\\nEmail\\nWolf Point West\\n343 W Wolf Point Plz, Chicago, IL 60654\\n1\\n/\\n23\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,973 - $14,446\\nStudio - 3 Beds\\nSpecials\\nPets Allowed\\nPool\\nIn Unit Washer & Dryer\\nWalk-In Closets\\nClubhouse\\nBalcony\\nDisposal\\n(312) 564-5523\\nEmail\\n465 North Park\\n465 N Park Dr, Chicago, IL 60611\\n1\\n/\\n44\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,675 - $5,890\\nStudio - 3 Beds\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nRefrigerator\\nIn Unit Washer & Dryer\\n(708) 725-1453\\nEmail\\nArrive Michigan Avenue\\n1326 S Michigan Ave, Chicago, IL 60605\\n1\\n/\\n100\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,170 - $6,585\\nStudio - 3 Beds\\n1 Month Free\\nPets Allowed\\nPool\\nDishwasher\\nIn Unit Washer & Dryer\\nRooftop Deck\\n(708) 683-3561\\nEmail\\nMarlowe\\n169 W Huron St, Chicago, IL 60654\\n1\\n/\\n88\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,192 - $9,680\\nStudio - 2 Beds\\nDiscounts\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nIn Unit Washer & Dryer\\nClubhouse\\n(844) 620-7978\\nEmail\\nOne Chicago\\n14 W Superior St, Chicago, IL 60654\\n1\\n/\\n53\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,719 - $17,191\\nStudio - 3 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nDishwasher\\nRefrigerator\\nKitchen\\n(708) 775-3996\\nEmail\\nCassidy on Canal\\n350 N Canal St, Chicago, IL 60606\\n1\\n/\\n172\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,312 - $11,147\\nStudio - 2 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nPool\\nHigh-Speed Internet\\nStainless Steel Appliances\\n(866) 850-8920\\nEmail\\nResidences at 8 East Huron\\n8 E Huron St, Chicago, IL 60611\\n1\\n/\\n7\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,975 - $11,495\\n1-3 Beds\\nFitness Center\\nPool\\nConcierge\\n(708) 393-2727\\nEmail\\nFisher Building Apartments\\n343 S Dearborn St, Chicago, IL 60604\\n1\\n/\\n123\\n3D Tours\\nVideos\\nVirtual Tour\\n$1,625 - $3,670\\nStudio - 3 Beds\\n1 Month Free\\nPets Allowed\\nFitness Center\\nKitchen\\nWalk-In Closets\\nRange\\nCableReady\\n(312) 685-4327\\nEmail\\nThe Belden Stratford\\n2300 N Lincoln Park, Chicago, IL 60614\\n1\\n/\\n58\\n3D Tours\\nVideos\\nVirtual Tour\\n$2,970 - $11,996\\nStudio - 2 Beds\\nSpecials\\nPets Allowed\\nFitness Center\\nDishwasher\\nRefrigerator\\nKitchen\\nIn Unit Washer & Dryer\\n(224) 470-7746\\nEmail\\nShowing 40 of 700 Results -\\nPage 1 of 18\\n1\\n2\\n3\\n4\\n5\\nNext\\nIllinois\\nCook County\\nChicago')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fdb176a-061c-4449-ad48-5367ceef7949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have enough information to provide a specific recommendation for a room in Chicago. The context provided includes addresses and a doorman's phone number, but it doesn't specify which type of accommodation or hotel is being referred to. I recommend searching online for \"best rooms in Chicago\" or checking websites like TripAdvisor for recommendations.\n"
     ]
    }
   ],
   "source": [
    "messages = {\n",
    "    \n",
    "        \"system\":\n",
    "        \"You are a confident world-class realtor. Don't say you don't know or have not enough information. Provide detailed information to the users about the apartments.\",\n",
    "        \"question\": \"I want you to recommend the room in LA\",\n",
    "}\n",
    "response = graph.invoke(messages)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a870738-9155-46cc-b66c-b515bd67c889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "126183b5-f670-4664-b5a2-584537fde8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57bbfe15-a2f1-4042-a738-3107b91eff88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching URL: https://www.apartment.com/search?q=2+bedroom+apartments+in+Los+Angeles\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     42\u001b[39m     user_query = \u001b[33m\"\u001b[39m\u001b[33m2 bedroom apartments in Los Angeles\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     result = \u001b[43msearch_apartment\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSearch Result:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36msearch_apartment\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Use the WebBaseLoader to load content from the constructed URL\u001b[39;00m\n\u001b[32m     22\u001b[39m loader = WebBaseLoader(search_url)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Build embeddings and vector store from the retrieved documents\u001b[39;00m\n\u001b[32m     26\u001b[39m embeddings = OllamaEmbeddings()  \u001b[38;5;66;03m# Ensure your OpenAI API key is set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/web_base.py:378\u001b[39m, in \u001b[36mWebBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Lazy load text from the url(s) in web_path.\"\"\"\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.web_paths:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     soup = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbs_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m     text = soup.get_text(**\u001b[38;5;28mself\u001b[39m.bs_get_text_kwargs)\n\u001b[32m    380\u001b[39m     metadata = _build_metadata(soup, path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/web_base.py:357\u001b[39m, in \u001b[36mWebBaseLoader._scrape\u001b[39m\u001b[34m(self, url, parser, bs_kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m         parser = \u001b[38;5;28mself\u001b[39m.default_parser\n\u001b[32m    355\u001b[39m \u001b[38;5;28mself\u001b[39m._check_parser(parser)\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m html_doc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_for_status:\n\u001b[32m    359\u001b[39m     html_doc.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/rag_tutorial/.venv/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1378\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1311\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1309\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1310\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1167\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def build_search_url(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Build the search URL from a user query.\n",
    "    Note: This URL structure is hypothetical. You’ll need to adjust the base URL\n",
    "    and query parameters based on how apartment.com constructs its search URLs.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.apartment.com/search\"  # Adjust as necessary\n",
    "    params = {\"q\": query}\n",
    "    search_url = f\"{base_url}?{urllib.parse.urlencode(params)}\"\n",
    "    return search_url\n",
    "\n",
    "def search_apartment(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a search query, build the URL, load the webpage content,\n",
    "    and then use a retrieval pipeline to extract relevant information.\n",
    "    \"\"\"\n",
    "    # Construct the search URL\n",
    "    search_url = build_search_url(query)\n",
    "    print(f\"Searching URL: {search_url}\")\n",
    "    \n",
    "    # Use the WebBaseLoader to load content from the constructed URL\n",
    "    loader = WebBaseLoader(search_url)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Build embeddings and vector store from the retrieved documents\n",
    "    embeddings = OllamaEmbeddings()  # Ensure your OpenAI API key is set\n",
    "    vectorstore = InMemoryVectorStore.from_documents(documents, embeddings)\n",
    "    \n",
    "    # Build the RetrievalQA pipeline using the vector store\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOllama(),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever()\n",
    "    )\n",
    "    \n",
    "    # Use the QA system to get an answer based on your original query\n",
    "    result = qa.run(query)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"2 bedroom apartments in Los Angeles\"\n",
    "    result = search_apartment(user_query)\n",
    "    print(\"Search Result:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9e5f5-5f4f-4ffd-801f-842694cb245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fe266-7edb-470b-aaf8-62a5e02bcbf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.apartment.com/search?q=2+bedroom+apartments+in+Los+Angeles'  # Replace with your target URL\n",
    "\n",
    "# Create a session with retry logic\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[500, 502, 503, 504],\n",
    "    allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "# Define headers to mimic a browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = session.get(url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error fetching the page:\", e)\n",
    "else:\n",
    "    # Parse and prettify the HTML with BeautifulSoup\n",
    "    only_placards = bs4.SoupStrainer(\"section\", attrs={\n",
    "    \"class\": \"placards placardsv2\",\n",
    "    \"id\": \"placards\",\n",
    "    \"data-nosnippet\": \"\"\n",
    "    })\n",
    "    soup = BeautifulSoup(response.text, 'html.parser', parse_only=only_placards)\n",
    "    print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500c7e9-b328-43e6-a500-8aa2cb144c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    \"\"\"\n",
    "    A custom web loader that fetches a webpage with custom headers and retry logic,\n",
    "    then filters the HTML to only include the <section> tag with the specified attributes.\n",
    "    The filtered HTML is returned as a LangChain Document object.\n",
    "    \"\"\"\n",
    "    def load(self):\n",
    "        # Define custom headers to mimic a browser.\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "        }\n",
    "        # Create a session with retry logic.\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()  # Check for HTTP errors.\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        \n",
    "        # Use SoupStrainer to filter only the desired <section> tag.\n",
    "        # filter_section = SoupStrainer(\"section\", attrs={\n",
    "        #     \"class\": \"placards placardsv2\",\n",
    "        #     \"id\": \"placards\",\n",
    "        #     \"data-nosnippet\": \"\"\n",
    "        # })\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\", \n",
    "            id=\"placardContainer\", \n",
    "            class_=\"placardContainer\", \n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section)\n",
    "        \n",
    "        # Prettify the filtered HTML (if found) and create a Document.\n",
    "        content = soup.prettify() if soup and soup.contents else \"\"\n",
    "        doc = Document(page_content=content, metadata={\"source\": self.web_path})\n",
    "        return [doc]\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    target_url = 'https://www.apartment.com/search?q=2+bedroom+apartments+in+Los+Angeles'\n",
    "    loader = CustomWebLoader(target_url)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    if documents and documents[0].page_content:\n",
    "        print(\"Filtered content:\")\n",
    "        print(documents[0].page_content)\n",
    "    else:\n",
    "        print(\"No matching content found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79759e86-d9e0-4d91-87d8-6cabc155b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8614783d-ae8b-4ab3-83b1-ed58fe60e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated URL: https://www.apartments.com/condos/los-angeles-ca/studios-over-1500/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define the data model with allowed values and defaults.\n",
    "class ApartmentQuery(BaseModel):\n",
    "    city: str = Field(\n",
    "        description=\"City with state abbreviation, e.g., 'Los Angeles, CA'\"\n",
    "    )\n",
    "    min_price: int = Field(\n",
    "        description=\"Minimum price as an integer, e.g., 1300\"\n",
    "    )\n",
    "    home_type: str = Field(\n",
    "        default=\"apartments\",\n",
    "        description=\"Home type: one of apartments, houses, condos, townhomes. Defaults to apartments.\"\n",
    "    )\n",
    "    bedrooms: str = Field(\n",
    "        default=\"2+\",\n",
    "        description=\"Bedroom filter: one of any, studio, 1+, 2+, 3+, 4+. Defaults to 2+.\"\n",
    "    )\n",
    "    bathrooms: str = Field(\n",
    "        default=\"1+\",\n",
    "        description=\"Bathroom filter: one of any, 1+, 2+, 3+. Defaults to 1+.\"\n",
    "    )\n",
    "\n",
    "# Set up the output parser for our Pydantic model.\n",
    "parser = PydanticOutputParser(pydantic_object=ApartmentQuery)\n",
    "\n",
    "# Create a prompt template that clearly instructs the model what JSON to output.\n",
    "prompt_template = \"\"\"\n",
    "You are a data extraction assistant. Extract the following details from the user's query:\n",
    "\n",
    "- city: The city with its state abbreviation (e.g., \"Los Angeles, CA\").\n",
    "- min_price: The minimum price as an integer (e.g., 1300).\n",
    "- home_type: The home type, choose from: apartments, houses, condos, townhomes. (Default: apartments)\n",
    "- bedrooms: The bedroom filter, choose from: any, studio, 1+, 2+, 3+, 4+. (Default: 2+)\n",
    "- bathrooms: The bathroom filter, choose from: any, 1+, 2+, 3+. (Default: 1+)\n",
    "\n",
    "Return your answer as a valid JSON object with exactly these keys: \"city\", \"min_price\", \"home_type\", \"bedrooms\", \"bathrooms\". Do not include any additional keys or text.\n",
    "\n",
    "Query: \"{query}\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Initialize ChatOllama with your local model.\n",
    "chat = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Chain the prompt, model, and parser.\n",
    "chain = prompt | chat | parser\n",
    "\n",
    "# Mapping functions for URL segments.\n",
    "def map_bedrooms(bedrooms: str) -> str:\n",
    "    bed_map = {\n",
    "        \"any\": \"\",\n",
    "        \"studio\": \"studios\",  # changed from \"studio\" to \"studios\"\n",
    "        \"1+\": \"min-1-bedrooms\",\n",
    "        \"2+\": \"min-2-bedrooms\",\n",
    "        \"3+\": \"min-3-bedrooms\",\n",
    "        \"4+\": \"min-4-bedrooms\"\n",
    "    }\n",
    "    return bed_map.get(bedrooms.lower().strip(), \"min-2-bedrooms\")\n",
    "\n",
    "def map_bathrooms(bathrooms: str) -> str:\n",
    "    bath_map = {\n",
    "        \"any\": \"\",\n",
    "        \"1+\": \"1-bathrooms\",\n",
    "        \"2+\": \"2-bathrooms\",\n",
    "        \"3+\": \"3-bathrooms\"\n",
    "    }\n",
    "    return bath_map.get(bathrooms.lower().strip(), \"1-bathrooms\")  # default to 1+\n",
    "\n",
    "# URL generator that produces the Apartments.com URL.\n",
    "def generate_apartments_url(params: ApartmentQuery) -> str:\n",
    "    # Create a city slug, e.g., \"Los Angeles, CA\" -> \"los-angeles-ca\"\n",
    "    city_slug = re.sub(r'[,\\s]+', '-', params.city.lower().strip())\n",
    "    \n",
    "    # Use the provided home_type if valid; otherwise, default to \"apartments\"\n",
    "    home_type_lower = params.home_type.lower().strip()\n",
    "    if home_type_lower not in [\"apartments\", \"houses\", \"condos\", \"townhomes\"]:\n",
    "        home_type_lower = \"apartments\"\n",
    "    \n",
    "    # Map bedrooms and bathrooms.\n",
    "    bedrooms_segment = map_bedrooms(params.bedrooms)\n",
    "    bathrooms_segment = map_bathrooms(params.bathrooms)\n",
    "    price_segment = f\"over-{params.min_price}\"\n",
    "    \n",
    "    # Build segments, omitting any empty segments.\n",
    "    segments = []\n",
    "    if bedrooms_segment:\n",
    "        segments.append(bedrooms_segment)\n",
    "    if bathrooms_segment:\n",
    "        segments.append(bathrooms_segment)\n",
    "    segments.append(price_segment)\n",
    "    \n",
    "    middle_segment = \"-\".join(segments)\n",
    "    \n",
    "    # Final URL format:\n",
    "    # Example: https://www.apartments.com/apartments/los-angeles-ca/min-2-bedrooms-1-bathrooms-over-1300/\n",
    "    return f\"https://www.apartments.com/{home_type_lower}/{city_slug}/{middle_segment}/\"\n",
    "\n",
    "# Example query.\n",
    "query = \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\"\n",
    "\n",
    "# Run the chain to extract parameters.\n",
    "parsed_result = chain.invoke({\n",
    "    \"query\": query,\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "# Generate the URL based on the parsed parameters.\n",
    "url = generate_apartments_url(parsed_result)\n",
    "\n",
    "print(\"Generated URL:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34d183-9ac1-4988-893b-3ad53780b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph import Graph\n",
    "\n",
    "graph = Graph()\n",
    "\n",
    "# Node for generating the prompt.\n",
    "def prompt_node(inputs: dict) -> dict:\n",
    "    # Merge query and format instructions from the parser.\n",
    "    formatted_prompt = prompt.format(\n",
    "        query=inputs[\"query\"],\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    return {\"prompt\": formatted_prompt}\n",
    "\n",
    "# Node for LLM call.\n",
    "def llm_node(inputs: dict) -> dict:\n",
    "    # Call the LLM with the generated prompt.\n",
    "    response = llm.call(inputs[\"prompt\"])\n",
    "    return {\"llm_output\": response}\n",
    "\n",
    "# Node for parsing the LLM output.\n",
    "def parser_node(inputs: dict) -> dict:\n",
    "    # Parse the JSON output from the LLM.\n",
    "    parsed = parser.parse(inputs[\"llm_output\"])\n",
    "    return {\"parsed\": parsed.dict()}  # convert to dict for the next node\n",
    "\n",
    "# Node for generating the URL.\n",
    "def url_node(inputs: dict) -> dict:\n",
    "    url = generate_apartments_url(inputs[\"parsed\"])\n",
    "    return {\"url\": url}\n",
    "\n",
    "# Add nodes to the graph.\n",
    "graph.add_node(\"Prompt\", prompt_node)\n",
    "graph.add_node(\"LLM\", llm_node)\n",
    "graph.add_node(\"Parser\", parser_node)\n",
    "graph.add_node(\"URLGenerator\", url_node)\n",
    "\n",
    "# Connect the nodes in order.\n",
    "graph.connect(\"Input\", \"Prompt\")\n",
    "graph.connect(\"Prompt\", \"LLM\")\n",
    "graph.connect(\"LLM\", \"Parser\")\n",
    "graph.connect(\"Parser\", \"URLGenerator\")\n",
    "\n",
    "# Sample input query.\n",
    "inputs = {\n",
    "    \"query\": \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\"\n",
    "}\n",
    "\n",
    "# Run the graph.\n",
    "result = graph.run(inputs)\n",
    "print(\"Generated URL:\", result[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d048878-49b8-4d6d-86cf-70f28e45d085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taejunsong/workspace/rag_tutorial/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/52k791n10qj37p5d0t3151w80000gn/T/ipykernel_72387/534467504.py:150: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return generate_apartments_url(parsed_params.dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated URL: https://www.apartments.com/condos/los-angeles-ca/min-2-bedrooms-over-1500/\n"
     ]
    }
   ],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Environment & Global Setup\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "root_dir = Path().resolve()\n",
    "print(root_dir.parent / '.env')\n",
    "\n",
    "config = Config(RepositoryEnv(root_dir.parent / '.env'))  # Explicitly load .env\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config('LANGSMITH_API_KEY')\n",
    "\n",
    "# We'll use two LLM instances:\n",
    "# 1. For URL generation using our new chain.\n",
    "llm_url = ChatOllama(model=\"llama3.2\")\n",
    "# 2. For the downstream QA process.\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# New LLM-based URL Generation Chain\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Define the structured schema for extracting URL parameters.\n",
    "class ApartmentQuery(BaseModel):\n",
    "    city: str = Field(\n",
    "        description=\"City with state abbreviation, e.g., 'Los Angeles, CA'\"\n",
    "    )\n",
    "    min_price: int = Field(\n",
    "        description=\"Minimum price as an integer, e.g., 1500\"\n",
    "    )\n",
    "    home_type: str = Field(\n",
    "        default=\"apartments\",\n",
    "        description=\"Home type: one of apartments, houses, condos, townhomes. Defaults to apartments.\"\n",
    "    )\n",
    "    bedrooms: str = Field(\n",
    "        default=\"2+\",\n",
    "        description=\"Bedroom filter: one of any, studio, 1+, 2+, 3+, 4+. For a studio, output 'studios'. Defaults to 2+.\"\n",
    "    )\n",
    "    bathrooms: str = Field(\n",
    "        default=\"1+\",\n",
    "        description=\"Bathroom filter: one of any, 1+, 2+, 3+. Defaults to 1+.\"\n",
    "    )\n",
    "\n",
    "# Set up the output parser.\n",
    "parser = PydanticOutputParser(pydantic_object=ApartmentQuery)\n",
    "\n",
    "# Define the prompt template for extracting the URL parameters.\n",
    "prompt_template = \"\"\"\n",
    "You are a data extraction assistant. Extract the following details from the user's query:\n",
    "- city: The city with its state abbreviation (e.g., \"Los Angeles, CA\").\n",
    "- min_price: The minimum price as an integer (e.g., 1500).\n",
    "- home_type: One of: apartments, houses, condos, townhomes. (Default: apartments)\n",
    "- bedrooms: One of: any, studio, 1+, 2+, 3+, 4+ (Default: 2+). For a studio, output \"studios\".\n",
    "- bathrooms: One of: any, 1+, 2+, 3+ (Default: 1+).\n",
    "\n",
    "Return your answer as a JSON object with exactly these keys: \"city\", \"min_price\", \"home_type\", \"bedrooms\", \"bathrooms\".\n",
    "Query: \"{query}\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Helper function to generate the URL based on extracted parameters.\n",
    "def generate_apartments_url(params: dict) -> str:\n",
    "    # Create a city slug: \"Los Angeles, CA\" -> \"los-angeles-ca\"\n",
    "    city_slug = re.sub(r'[,\\s]+', '-', params[\"city\"].lower().strip())\n",
    "    \n",
    "    home_type_lower = params[\"home_type\"].lower().strip()\n",
    "    if home_type_lower not in [\"apartments\", \"houses\", \"condos\", \"townhomes\"]:\n",
    "        home_type_lower = \"apartments\"\n",
    "    \n",
    "    # Map bedroom filter (note: for a studio, we want \"studios\")\n",
    "    bed_map = {\n",
    "        \"any\": \"\",\n",
    "        \"studio\": \"studios\",\n",
    "        \"1+\": \"min-1-bedrooms\",\n",
    "        \"2+\": \"min-2-bedrooms\",\n",
    "        \"3+\": \"min-3-bedrooms\",\n",
    "        \"4+\": \"min-4-bedrooms\"\n",
    "    }\n",
    "    bedroom_seg = bed_map.get(params[\"bedrooms\"].lower().strip(), \"min-2-bedrooms\")\n",
    "    \n",
    "    # Map bathroom filter.\n",
    "    bath_map = {\n",
    "        \"any\": \"\",\n",
    "        \"1+\": \"1-bathrooms\",\n",
    "        \"2+\": \"2-bathrooms\",\n",
    "        \"3+\": \"3-bathrooms\"\n",
    "    }\n",
    "    bathroom_seg = bath_map.get(params[\"bathrooms\"].lower().strip(), \"1-bathrooms\")\n",
    "    \n",
    "    price_segment = f\"over-{params['min_price']}\"\n",
    "    \n",
    "    segments = []\n",
    "    if bedroom_seg:\n",
    "        segments.append(bedroom_seg)\n",
    "    if bathroom_seg:\n",
    "        segments.append(bathroom_seg)\n",
    "    segments.append(price_segment)\n",
    "    middle_segment = \"-\".join(segments)\n",
    "    \n",
    "    # Final URL format matching apartments.com:\n",
    "    return f\"https://www.apartments.com/{home_type_lower}/{city_slug}/{middle_segment}/\"\n",
    "\n",
    "# The new build_search_url function that uses our LLM-based URL generation.\n",
    "\n",
    "def parse_json_with_stripped_keys(text: str) -> dict:\n",
    "    # Parse the JSON string\n",
    "    data = json.loads(text)\n",
    "    # Strip whitespace from all keys\n",
    "    return {k.strip(): v for k, v in data.items()}\n",
    "\n",
    "def build_search_url(query: str) -> str:\n",
    "    formatted_prompt = prompt.format(\n",
    "        query=query,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    llm_response = llm_url.invoke(formatted_prompt)\n",
    "    response_text = llm_response.content if hasattr(llm_response, \"content\") else str(llm_response)\n",
    "    # Clean the JSON output by stripping whitespace from keys\n",
    "    fixed_data = parse_json_with_stripped_keys(response_text)\n",
    "    # Create the Pydantic model using the cleaned dictionary\n",
    "    parsed_params = ApartmentQuery(**fixed_data)\n",
    "    return generate_apartments_url(parsed_params.dict())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Custom Web Loader (unchanged)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    \"\"\"\n",
    "    A custom web loader that fetches a webpage with custom headers and retry logic,\n",
    "    then filters the HTML to only include the desired content.\n",
    "    Returns a LangChain Document.\n",
    "    \"\"\"\n",
    "    def load(self):\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "        }\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        \n",
    "        # Filter the HTML to the desired section.\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\", \n",
    "            id=\"placardContainer\", \n",
    "            class_=\"placardContainer\", \n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        content = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section).get_text(separator=\"\\n\", strip=True)\n",
    "        doc = Document(page_content=content, metadata={\"source\": self.web_path})\n",
    "        return [doc]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Downstream Processing: Load, Chunk, Index, & QA Graph\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Use the new build_search_url function to get the Apartments.com URL.\n",
    "user_query = \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\"\n",
    "target_url = build_search_url(user_query)\n",
    "print(\"Generated URL:\", target_url)\n",
    "\n",
    "loader = CustomWebLoader(target_url)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=30, chunk_overlap=10)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering from hub.\n",
    "prompt_qa = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define application state.\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Step: Retrieve documents from the vector store.\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "# Step: Generate an answer using the QA prompt and LLM.\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_qa.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Build the LangGraph application.\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "messages = {\n",
    "        \"system\":\n",
    "        \"You are a confident world-class realtor. Don't say you don't know or have not enough information. Provide detailed information to the users about the apartments.\",\n",
    "        \"question\": user_query,\n",
    "}\n",
    "response = graph.invoke(messages)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19e50b54-9107-4747-afe6-6947f82d0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have specific information on condo listings in Los Angeles that meet your criteria. However, I can suggest searching online platforms such as Zillow or Redfin for condos with studio options, priced over $1,500, and any bathrooms in Los Angeles, CA, that also allow pets and are furnished. This will provide you with a more comprehensive list of potential options.\n"
     ]
    }
   ],
   "source": [
    "messages = {\n",
    "        \"system\":\n",
    "        \"You are a confident world-class realtor. Don't say you don't know or have not enough information. Provide detailed information to the users about the apartments.\",\n",
    "        \"question\": user_query,\n",
    "}\n",
    "response = graph.invoke(messages)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ea2f49b-2437-44fe-b12f-1b03814aac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.apartments.com/condos/los-angeles-ca/min-2-bedrooms-over-1500/'}, page_content='2 Bedroom Condos for Rent in Los Angeles CA - 8,839 Rentals\\n11929 Courtleigh Dr Unit 310\\n11929 Courtleigh Dr Unit 310, Los Angeles, CA 90066\\n1\\n/\\n27\\n$4,399\\n2 Beds, 2 Baths, 1,210 sq ft\\n(213) 263-4293\\nEmail\\n611 Levering Ave Unit FL2-ID1306\\n611 Levering Ave Unit FL2-ID1306, Los Angeles, CA 90024\\n1\\n/\\n22\\n3D Tours\\nVirtual Tour\\n$3,630\\n2 Beds, 1 Bath, 950 sq ft\\nPets Allowed\\nFurnished\\n(424) 239-1315\\nEmail\\n6923 Kittyhawk Ave Unit 202\\n6923 Kittyhawk Ave Unit 202, Los Angeles, CA 90045\\n1\\n/\\n11\\n$3,399\\n2 Beds, 2 Baths, 1,105 sq ft\\n(213) 722-3401\\nEmail\\n5342 Fountain Ave Unit 404\\n5342 Fountain Ave Unit 404, Los Angeles, CA 90029\\n$2,995\\n2 Beds, 2 Baths, 1,000 sq ft\\n(213) 698-5379\\nEmail\\n10983 Bluffside Dr Unit FL2-ID1320\\n10983 Bluffside Dr Unit FL2-ID1320, Los Angeles, CA 91604\\n1\\n/\\n8\\n$3,900\\n2 Beds, 2 Baths, 990 sq ft\\nPets Allowed\\nBalcony\\nFurnished\\nFitness Center\\n(747) 966-5316\\nEmail\\n5500 Klump Ave Unit FL5-ID921\\n5500 Klump Ave Unit FL5-ID921, Los Angeles, CA 91601\\n1\\n/\\n38\\n3D Tours\\nVirtual Tour\\n$3,350\\n2 Beds, 2 Baths, 1,080 sq ft\\nPets Allowed\\nBalcony\\nFurnished\\nFitness Center\\n(747) 277-0288\\nEmail\\n1010 Wilshire Blvd Unit FL13-ID1040\\n1010 Wilshire Blvd Unit FL13-ID1040, Los Angeles, CA 90017\\n1\\n/\\n39\\n3D Tours\\nVirtual Tour\\n$2,640\\n2 Beds, 1 Bath, 1,045 sq ft\\nPets Allowed\\nFurnished\\nDoorman\\nFitness Center\\n(213) 320-5342\\nEmail\\n7660 Beverly Blvd Unit FL1-ID1100\\n7660 Beverly Blvd Unit FL1-ID1100, Los Angeles, CA 90036\\n1\\n/\\n43\\n3D Tours\\nVirtual Tour\\n$4,460\\n2 Beds, 2 Baths, 991 sq ft\\nPets Allowed\\nBalcony\\nFurnished\\nFitness Center\\n(424) 239-1488\\nEmail\\n5620 De Longpre Ave Unit FL6-ID1113\\n5620 De Longpre Ave Unit FL6-ID1113, Los Angeles, CA 90028\\n1\\n/\\n48\\n3D Tours\\nVirtual Tour\\n$3,840\\n2 Beds, 2 Baths, 1,087 sq ft\\nPets Allowed\\nFurnished\\nRooftop Deck\\nFitness Center\\n(213) 298-3981\\nEmail\\n5966-5968 W 86th Pl Unit 5968\\n5966-5968 W 86th Pl Unit 5968, Los Angeles, CA 90045\\n1\\n/\\n27\\n$7,600\\n4 Beds, 4 Baths, 2,050 sq ft\\n(213) 335-3104\\nEmail\\n5966-5968 W 86th Pl Unit 5966\\n5966-5968 W 86th Pl Unit 5966, Los Angeles, CA 90045\\n1\\n/\\n37\\n$8,495\\n4 Beds, 4 Baths, 2,200 sq ft\\n(424) 588-6387\\nEmail\\n8341-8343 Dunbarton Avenue\\n8341-8343 Dunbarton Ave Unit 8343, Los Angeles, CA 90045\\n1\\n/\\n31\\n$7,600\\n4 Beds, 3 Baths, 1,850 sq ft\\n(623) 404-8198\\nEmail\\n255 S Ave 55 Unit 12\\n255 S Ave 55 Unit 12, Los Angeles, CA 90042\\n1\\n/\\n12\\n$2,495\\n2 Beds, 2 Baths, 650 sq ft\\n(213) 667-0721\\nEmail\\n6923 Kittyhawk Ave Unit 402\\n6923 Kittyhawk Ave Unit 402, Los Angeles, CA 90045\\n1\\n/\\n22\\n$3,300\\n2 Beds, 2 Baths, 1,150 sq ft\\n(213) 523-3705\\nEmail\\n3510 Clarington Ave Unit 01\\n3510 Clarington Ave Unit 01, Los Angeles, CA 90034\\n1\\n/\\n15\\n$2,650\\n2 Beds, 1 Bath, 950 sq ft\\n(213) 667-0223\\nEmail\\n7424 Haskell Ave Unit 309\\n7424 Haskell Ave Unit 309, Los Angeles, CA 91406\\n1\\n/\\n16\\n$2,385\\n2 Beds, 1 Bath\\n(213) 320-6807\\nEmail\\n7424 Haskell Ave Unit 204\\n7424 Haskell Ave Unit 204, Los Angeles, CA 91406\\n1\\n/\\n18\\n$2,385\\n2 Beds, 1 Bath\\n(213) 660-4961\\nEmail\\n12750 Matteson Ave Unit 7\\n12750 Matteson Ave Unit 7, Los Angeles, CA 90066\\n1\\n/\\n16\\n$2,625\\n2 Beds, 2 Baths, 925 sq ft\\n(213) 320-4755\\nEmail\\n2104 Hauser Blvd Unit 2104 1/2 Hauser Blvd.\\n2104 Hauser Blvd Unit 2104 1/2 Hauser Blvd., Los Angeles, CA 90016\\n1\\n/\\n21\\n$3,999\\n3 Beds, 3.5 Baths, 1,415 sq ft\\n(424) 380-6621\\nEmail\\n5342 Fountain Ave Unit 201\\n5342 Fountain Ave Unit 201, Los Angeles, CA 90029\\n$2,895\\n2 Beds, 2 Baths, 1,050 sq ft\\n(818) 666-2704\\nEmail\\n2847 Leeward Ave Unit FL3-ID1264\\n2847 Leeward Ave Unit FL3-ID1264, Los Angeles, CA 90005\\n1\\n/\\n40\\n3D Tours\\nVirtual Tour\\n$3,060\\n2 Beds, 2 Baths, 1,200 sq ft\\nPets Allowed\\nFurnished\\nRooftop Deck\\nFitness Center\\n(213) 528-4962\\nEmail\\n10876 Palms Blvd Unit 06\\n10876 Palms Blvd Unit 06, Los Angeles, CA 90034\\n1\\n/\\n20\\n$2,900\\n2 Beds, 2 Baths, 995 sq ft\\n(213) 873-3612\\nEmail\\n5342 Fountain Ave Unit 104\\n5342 Fountain Ave Unit 104, Los Angeles, CA 90029\\n$2,795\\n2 Beds, 2 Baths, 1,000 sq ft\\n(213) 568-6531\\nEmail\\n6548-6550 W 86th Pl Unit 6548\\n6548-6550 W 86th Pl Unit 6548, Los Angeles, CA 90045\\n1\\n/\\n21\\n$7,800\\n4 Beds, 4 Baths, 2,050 sq ft\\n(213) 566-1738\\nEmail\\n8385 Dunbarton Ave Unit 8385\\n8385 Dunbarton Ave Unit 8385, Los Angeles, CA 90045\\n1\\n/\\n24\\n$8,500\\n4 Beds, 4 Baths, 2,200 sq ft\\n(623) 253-8288\\nEmail\\n3729 Clarington Ave Unit 04\\n3729 Clarington Ave Unit 04, Los Angeles, CA 90034\\n1\\n/\\n19\\n$2,750\\n2 Beds, 2 Baths, 950 sq ft\\n(424) 543-6418\\nEmail\\n11600 Santa Monica Blvd Unit FL2-ID1201\\n11600 Santa Monica Blvd Unit FL2-ID1201, Los Angeles, CA 90025\\n1\\n/\\n34\\n3D Tours\\nVirtual Tour\\n$4,410\\n2 Beds, 1 Bath, 825 sq ft\\nFurnished\\nRooftop Deck\\nFitness Center\\n(424) 369-0376\\nEmail\\n132 S Mountain View Ave Unit 134\\n132 S Mountain View Ave Unit 134, Los Angeles, CA 90057\\n1\\n/\\n22\\n$2,975\\n3 Beds, 2 Baths\\n(213) 577-2680\\nEmail\\n132 S Mountain View Ave Unit 132\\n132 S Mountain View Ave Unit 132, Los Angeles, CA 90057\\n1\\n/\\n22\\n$2,975\\n3 Beds, 2 Baths\\n(213) 816-9680\\nEmail\\n11402 Washington Pl Unit A\\n11402 Washington Pl Unit A, Los Angeles, CA 90066\\n1\\n/\\n16\\n$3,150\\n2 Beds, 1 Bath, 870 sq ft\\n(424) 419-1294\\nEmail\\n1155 S Westmoreland Ave Unit 202\\n1155 S Westmoreland Ave Unit 202, Los Angeles, CA 90006\\n1\\n/\\n19\\n$3,700\\n3 Beds, 2 Baths, 1,290 sq ft\\nDogs Allowed\\nBalcony\\nWalk-In Closets\\nHardwood Floors\\nSmoke Free\\nDen\\nWheelchair Accessible\\n(213) 577-1191\\nEmail\\n11505 Riverside Dr Unit 206\\n11505 Riverside Dr Unit 206, Los Angeles, CA 91602\\n1\\n/\\n18\\n$2,450\\n2 Beds, 2 Baths, 950 sq ft\\n(747) 277-0131\\nEmail\\n11505 Riverside Dr Unit 406\\n11505 Riverside Dr Unit 406, Los Angeles, CA 91602\\n1\\n/\\n17\\n$2,450\\n2 Beds, 2 Baths, 950 sq ft\\n(747) 285-8715\\nEmail\\n12338 Oxnard St Unit 204\\n12338 Oxnard St Unit 204, Los Angeles, CA 91606\\n1\\n/\\n18\\n$2,395\\n2 Beds, 2 Baths, 909 sq ft\\n(747) 339-8865\\nEmail\\n12241 Burbank Blvd Unit 201\\n12241 Burbank Blvd Unit 201, Los Angeles, CA 91607\\n1\\n/\\n15\\n$2,695\\n2 Beds, 2 Baths, 1,080 sq ft\\n(747) 277-7837\\nEmail\\n425 N Alvarado St Unit 106\\n425 N Alvarado St Unit 106, Los Angeles, CA 90026\\n1\\n/\\n19\\n$3,095\\n2 Beds, 2 Baths, 860 sq ft\\n(213) 568-6977\\nEmail\\n3960 Carpenter Ave Unit 07\\n3960 Carpenter Ave Unit 07, Los Angeles, CA 91604\\n1\\n/\\n25\\n$3,295\\n2 Beds, 2 Baths, 1,311 sq ft\\n(747) 207-3117\\nEmail\\n3960 Carpenter Ave Unit 306\\n3960 Carpenter Ave Unit 306, Los Angeles, CA 91604\\n1\\n/\\n21\\n$3,195\\n2 Beds, 2 Baths, 1,311 sq ft\\n(747) 326-5527\\nEmail\\n3960 Carpenter Ave Unit 209\\n3960 Carpenter Ave Unit 209, Los Angeles, CA 91604\\n1\\n/\\n18\\n$3,195\\n2 Beds, 2 Baths, 1,311 sq ft\\n(747) 318-3435\\nEmail\\n11225 Huston St Unit 207\\n11225 Huston St Unit 207, Los Angeles, CA 91601\\n1\\n/\\n12\\n$2,495\\n2 Beds, 2 Baths, 953 sq ft\\n(747) 746-4015\\nEmail\\nShowing 40 of 700 Results -\\nPage 1 of 18\\n1\\n2\\n3\\n4\\n5\\nNext\\nCondos\\nCalifornia\\nLos Angeles County\\nLos Angeles')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b0a01397-3459-4358-b929-050bb1134b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taejunsong/workspace/rag_tutorial/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/52k791n10qj37p5d0t3151w80000gn/T/ipykernel_72387/545242190.py:146: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return generate_apartments_url(parsed_params.dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated URL: https://www.apartments.com/condos/los-angeles-ca/min-2-bedrooms-over-1500/\n",
      "QA Answer: I don't know the specific condos in Los Angeles, CA that meet your criteria of having studio options, priced over $1500, and any bathrooms. The provided context suggests that multiple condo listings are available with similar features, but without more information or specific details about each listing, it's difficult to provide a precise answer. You may want to visit a real estate website or consult with a property manager for more tailored results.\n"
     ]
    }
   ],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import urllib.parse\n",
    "import json\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph  # For future extension with a full graph.\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Environment & Global Setup\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "root_dir = Path().resolve()\n",
    "print(root_dir.parent / '.env')\n",
    "\n",
    "config = Config(RepositoryEnv(root_dir.parent / '.env'))  # Explicitly load .env\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config('LANGSMITH_API_KEY')\n",
    "\n",
    "# Initialize two LLM instances:\n",
    "# 1. For URL generation.\n",
    "llm_url = ChatOllama(model=\"llama3.2\")\n",
    "# 2. For downstream QA.\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LLM-based URL Generation Chain\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Define the structured schema for URL parameters.\n",
    "class ApartmentQuery(BaseModel):\n",
    "    city: str = Field(description=\"City with state abbreviation, e.g., 'Los Angeles, CA'\")\n",
    "    min_price: int = Field(description=\"Minimum price as an integer, e.g., 1500\")\n",
    "    home_type: str = Field(\n",
    "        default=\"apartments\",\n",
    "        description=\"Home type: one of apartments, houses, condos, townhomes. Defaults to apartments.\"\n",
    "    )\n",
    "    bedrooms: str = Field(\n",
    "        default=\"2+\",\n",
    "        description=\"Bedroom filter: one of any, studio, 1+, 2+, 3+, 4+. For a studio, output 'studios'. Defaults to 2+.\"\n",
    "    )\n",
    "    bathrooms: str = Field(\n",
    "        default=\"1+\",\n",
    "        description=\"Bathroom filter: one of any, 1+, 2+, 3+. Defaults to 1+.\"\n",
    "    )\n",
    "\n",
    "# Set up the output parser.\n",
    "parser = PydanticOutputParser(pydantic_object=ApartmentQuery)\n",
    "\n",
    "# Define a prompt template that extracts exactly the required fields.\n",
    "prompt_template = \"\"\"\n",
    "You are a data extraction assistant. Extract the following details from the user's query:\n",
    "- city: The city with its state abbreviation (e.g., \"Los Angeles, CA\").\n",
    "- min_price: The minimum price as an integer (e.g., 1500).\n",
    "- home_type: One of: apartments, houses, condos, townhomes. (Default: apartments)\n",
    "- bedrooms: One of: any, studio, 1+, 2+, 3+, 4+ (Default: 2+). For a studio, output \"studios\".\n",
    "- bathrooms: One of: any, 1+, 2+, 3+ (Default: 1+).\n",
    "\n",
    "Return your answer as a JSON object with exactly these keys: \"city\", \"min_price\", \"home_type\", \"bedrooms\", \"bathrooms\".\n",
    "Query: \"{query}\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def generate_apartments_url(params: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build the Apartments.com URL using the provided parameters.\n",
    "    \"\"\"\n",
    "    # Create a slug for the city (e.g., \"Los Angeles, CA\" -> \"los-angeles-ca\")\n",
    "    city_slug = re.sub(r'[,\\s]+', '-', params[\"city\"].lower().strip())\n",
    "    \n",
    "    # Validate home type; default to apartments if not valid.\n",
    "    home_type_lower = params[\"home_type\"].lower().strip()\n",
    "    if home_type_lower not in [\"apartments\", \"houses\", \"condos\", \"townhomes\"]:\n",
    "        home_type_lower = \"apartments\"\n",
    "    \n",
    "    # Map bedroom filter (ensuring \"studio\" becomes \"studios\")\n",
    "    bed_map = {\n",
    "        \"any\": \"\",\n",
    "        \"studio\": \"studios\",\n",
    "        \"1+\": \"min-1-bedrooms\",\n",
    "        \"2+\": \"min-2-bedrooms\",\n",
    "        \"3+\": \"min-3-bedrooms\",\n",
    "        \"4+\": \"min-4-bedrooms\"\n",
    "    }\n",
    "    bedroom_seg = bed_map.get(params[\"bedrooms\"].lower().strip(), \"min-2-bedrooms\")\n",
    "    \n",
    "    # Map bathroom filter.\n",
    "    bath_map = {\n",
    "        \"any\": \"\",\n",
    "        \"1+\": \"1-bathrooms\",\n",
    "        \"2+\": \"2-bathrooms\",\n",
    "        \"3+\": \"3-bathrooms\"\n",
    "    }\n",
    "    bathroom_seg = bath_map.get(params[\"bathrooms\"].lower().strip(), \"1-bathrooms\")\n",
    "    \n",
    "    price_segment = f\"over-{params['min_price']}\"\n",
    "    segments = []\n",
    "    if bedroom_seg:\n",
    "        segments.append(bedroom_seg)\n",
    "    if bathroom_seg:\n",
    "        segments.append(bathroom_seg)\n",
    "    segments.append(price_segment)\n",
    "    middle_segment = \"-\".join(segments)\n",
    "    \n",
    "    return f\"https://www.apartments.com/{home_type_lower}/{city_slug}/{middle_segment}/\"\n",
    "\n",
    "def parse_json_with_stripped_keys(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load a JSON string and strip whitespace from its keys.\n",
    "    \"\"\"\n",
    "    data = json.loads(text)\n",
    "    return {k.strip(): v for k, v in data.items()}\n",
    "\n",
    "def build_search_url(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Build the search URL by using the LLM to extract query parameters and generating the URL.\n",
    "    \"\"\"\n",
    "    formatted_prompt = prompt.format(\n",
    "        query=query,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    llm_response = llm_url.invoke(formatted_prompt)\n",
    "    response_text = llm_response.content if hasattr(llm_response, \"content\") else str(llm_response)\n",
    "    fixed_data = parse_json_with_stripped_keys(response_text)\n",
    "    parsed_params = ApartmentQuery(**fixed_data)\n",
    "    return generate_apartments_url(parsed_params.dict())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Custom Web Loader\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    \"\"\"\n",
    "    Custom web loader that fetches a webpage with retry logic and filters content.\n",
    "    \"\"\"\n",
    "    def load(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\",\n",
    "            id=\"placardContainer\",\n",
    "            class_=\"placardContainer\",\n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        content = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section)\\\n",
    "            .get_text(separator=\"\\n\", strip=True)\n",
    "        return [Document(page_content=content, metadata={\"source\": self.web_path})]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Downstream Processing: Indexing & QA Pipeline\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Use the new build_search_url to get the target URL.\n",
    "user_query = \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\"\n",
    "target_url = build_search_url(user_query)\n",
    "print(\"Generated URL:\", target_url)\n",
    "\n",
    "# Load the webpage content.\n",
    "loader = CustomWebLoader(target_url)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the document into chunks.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=30, chunk_overlap=10)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Pull the QA prompt.\n",
    "prompt_qa = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define the application state.\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Step 1: Retrieve documents from the vector store.\n",
    "def retrieve(state: State) -> State:\n",
    "    state[\"context\"] = vector_store.similarity_search(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "# Step 2: Generate an answer using the QA prompt and LLM.\n",
    "def generate(state: State) -> State:\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_qa.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    state[\"answer\"] = llm.invoke(messages).content\n",
    "    return state\n",
    "\n",
    "# If a full LangGraph state graph isn’t callable in your version,\n",
    "# you can manually chain the steps in a helper function.\n",
    "def run_pipeline(state: State) -> State:\n",
    "    state = retrieve(state)\n",
    "    state = generate(state)\n",
    "    return state\n",
    "\n",
    "# Run the QA pipeline with the user query.\n",
    "initial_state: State = {\"question\": user_query, \"context\": [], \"answer\": \"\"}\n",
    "result_state = run_pipeline(initial_state)\n",
    "print(\"QA Answer:\", result_state[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6fafb13a-523c-4f59-a1ae-43824b68514c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taejunsong/workspace/rag_tutorial/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/52k791n10qj37p5d0t3151w80000gn/T/ipykernel_72387/3771287935.py:139: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return generate_apartments_url(parsed_params.dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated URL: https://www.apartments.com/condos/los-angeles-ca/min-2-bedrooms-over-1500/\n",
      "QA Answer: I recommend the first condo listing:\n",
      "\n",
      "**123 Main St, Apt 3B**\n",
      "\n",
      "Here's detailed information about this condo:\n",
      "\n",
      "* **Unit Type:** 1 bedroom, 1 bathroom condo\n",
      "* **Amenities:**\n",
      "\t+ Pets allowed (under 20 lbs, $50/month pet fee)\n",
      "\t+ Furnished with:\n",
      "\t\t- Queen-sized bed and mattress\n",
      "\t\t- Dresser and nightstand\n",
      "\t\t- Sofa bed in living room\n",
      "\t\t- Coffee table and TV stand\n",
      "* **Building Features:**\n",
      "\t+ In-unit laundry\n",
      "\t+ Central air conditioning\n",
      "\t+ Elevator access to all floors\n",
      "\t+ Secure entry with intercom system\n",
      "* **Neighborhood:**\n",
      "\t+ Located in the heart of downtown, within walking distance to shops, restaurants, and entertainment options\n",
      "\t+ Close proximity to public transportation and bike lanes\n",
      "* **Lease Terms:** 12-month lease, rent includes utilities (heating, cooling, water)\n"
     ]
    }
   ],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import urllib.parse\n",
    "import json\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph  # For potential future extension.\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Environment & Global Setup\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "root_dir = Path().resolve()\n",
    "print(root_dir.parent / '.env')\n",
    "\n",
    "config = Config(RepositoryEnv(root_dir.parent / '.env'))  # Explicitly load .env\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config('LANGSMITH_API_KEY')\n",
    "\n",
    "# Initialize two LLM instances:\n",
    "# 1. For URL generation.\n",
    "llm_url = ChatOllama(model=\"llama3.2\")\n",
    "# 2. For downstream QA.\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LLM-based URL Generation Chain\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class ApartmentQuery(BaseModel):\n",
    "    city: str = Field(\n",
    "        description=\"City with state abbreviation, e.g., 'Los Angeles, CA'\"\n",
    "    )\n",
    "    min_price: int = Field(\n",
    "        description=\"Minimum price as an integer, e.g., 1500\"\n",
    "    )\n",
    "    home_type: str = Field(\n",
    "        default=\"apartments\",\n",
    "        description=\"Home type: one of apartments, houses, condos, townhomes. Defaults to apartments.\"\n",
    "    )\n",
    "    bedrooms: str = Field(\n",
    "        default=\"2+\",\n",
    "        description=\"Bedroom filter: one of any, studio, 1+, 2+, 3+, 4+. For a studio, output 'studios'. Defaults to 2+.\"\n",
    "    )\n",
    "    bathrooms: str = Field(\n",
    "        default=\"1+\",\n",
    "        description=\"Bathroom filter: one of any, 1+, 2+, 3+. Defaults to 1+.\"\n",
    "    )\n",
    "\n",
    "# Set up the output parser.\n",
    "parser = PydanticOutputParser(pydantic_object=ApartmentQuery)\n",
    "\n",
    "# Define a prompt template for extracting URL parameters.\n",
    "prompt_template = \"\"\"\n",
    "You are a data extraction assistant. Extract the following details from the user's query:\n",
    "- city: The city with its state abbreviation (e.g., \"Los Angeles, CA\").\n",
    "- min_price: The minimum price as an integer (e.g., 1500).\n",
    "- home_type: One of: apartments, houses, condos, townhomes. (Default: apartments)\n",
    "- bedrooms: One of: any, studio, 1+, 2+, 3+, 4+ (Default: 2+). For a studio, output \"studios\".\n",
    "- bathrooms: One of: any, 1+, 2+, 3+ (Default: 1+).\n",
    "\n",
    "Return your answer as a JSON object with exactly these keys: \"city\", \"min_price\", \"home_type\", \"bedrooms\", \"bathrooms\".\n",
    "Query: \"{query}\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def generate_apartments_url(params: dict) -> str:\n",
    "    # Create a slug for the city.\n",
    "    city_slug = re.sub(r'[,\\s]+', '-', params[\"city\"].lower().strip())\n",
    "    \n",
    "    home_type_lower = params[\"home_type\"].lower().strip()\n",
    "    if home_type_lower not in [\"apartments\", \"houses\", \"condos\", \"townhomes\"]:\n",
    "        home_type_lower = \"apartments\"\n",
    "    \n",
    "    # Map bedroom filter (with \"studio\" turning into \"studios\")\n",
    "    bed_map = {\n",
    "        \"any\": \"\",\n",
    "        \"studio\": \"studios\",\n",
    "        \"1+\": \"min-1-bedrooms\",\n",
    "        \"2+\": \"min-2-bedrooms\",\n",
    "        \"3+\": \"min-3-bedrooms\",\n",
    "        \"4+\": \"min-4-bedrooms\"\n",
    "    }\n",
    "    bedroom_seg = bed_map.get(params[\"bedrooms\"].lower().strip(), \"min-2-bedrooms\")\n",
    "    \n",
    "    # Map bathroom filter.\n",
    "    bath_map = {\n",
    "        \"any\": \"\",\n",
    "        \"1+\": \"1-bathrooms\",\n",
    "        \"2+\": \"2-bathrooms\",\n",
    "        \"3+\": \"3-bathrooms\"\n",
    "    }\n",
    "    bathroom_seg = bath_map.get(params[\"bathrooms\"].lower().strip(), \"1-bathrooms\")\n",
    "    \n",
    "    price_segment = f\"over-{params['min_price']}\"\n",
    "    segments = []\n",
    "    if bedroom_seg:\n",
    "        segments.append(bedroom_seg)\n",
    "    if bathroom_seg:\n",
    "        segments.append(bathroom_seg)\n",
    "    segments.append(price_segment)\n",
    "    middle_segment = \"-\".join(segments)\n",
    "    \n",
    "    return f\"https://www.apartments.com/{home_type_lower}/{city_slug}/{middle_segment}/\"\n",
    "\n",
    "def parse_json_with_stripped_keys(text: str) -> dict:\n",
    "    data = json.loads(text)\n",
    "    return {k.strip(): v for k, v in data.items()}\n",
    "\n",
    "def build_search_url(query: str) -> str:\n",
    "    formatted_prompt = prompt.format(\n",
    "        query=query,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    llm_response = llm_url.invoke(formatted_prompt)\n",
    "    response_text = llm_response.content if hasattr(llm_response, \"content\") else str(llm_response)\n",
    "    fixed_data = parse_json_with_stripped_keys(response_text)\n",
    "    parsed_params = ApartmentQuery(**fixed_data)\n",
    "    return generate_apartments_url(parsed_params.dict())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Custom Web Loader\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    \"\"\"\n",
    "    Custom web loader that fetches a webpage with retry logic and filters content.\n",
    "    \"\"\"\n",
    "    def load(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\",\n",
    "            id=\"placardContainer\",\n",
    "            class_=\"placardContainer\",\n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        content = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section)\\\n",
    "            .get_text(separator=\"\\n\", strip=True)\n",
    "        return [Document(page_content=content, metadata={\"source\": self.web_path})]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Downstream Processing: Indexing & QA Pipeline\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Use the new build_search_url function.\n",
    "user_query = \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\"\n",
    "target_url = build_search_url(user_query)\n",
    "print(\"Generated URL:\", target_url)\n",
    "\n",
    "loader = CustomWebLoader(target_url)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=30, chunk_overlap=10)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Instead of using the hub prompt, we define our own QA prompt messages.\n",
    "def generate(state: dict) -> dict:\n",
    "    # Combine the content of all retrieved documents.\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a confident, world-class realtor who has just crawled the website in real time. \"\n",
    "                \"Based on the provided context, pick one specific condo listing that meets the criteria \"\n",
    "                \"and provide detailed, specific information about it. Do not hedge or mention uncertainty.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Based on the following context, please recommend one specific condo listing:\\n\\n{docs_content}\"\n",
    "        }\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    state[\"answer\"] = response.content\n",
    "    return state\n",
    "\n",
    "# Simple retrieval step: search the vector store using the question.\n",
    "def retrieve(state: dict) -> dict:\n",
    "    state[\"context\"] = vector_store.similarity_search(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "# Define application state.\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Manually chain the steps.\n",
    "def run_pipeline(state: State) -> State:\n",
    "    state = retrieve(state)\n",
    "    state = generate(state)\n",
    "    return state\n",
    "\n",
    "initial_state: State = {\"question\": user_query, \"context\": [], \"answer\": \"\"}\n",
    "result_state = run_pipeline(initial_state)\n",
    "print(\"QA Answer:\", result_state[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5f0d55b-6ded-48e7-a29c-9039b5f7d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taejunsong/workspace/rag_tutorial/.env\n",
      "Failed to decode JSON from LLM response. Response text:\n",
      "{ city: \"Los Angeles, CA\", min_price: 1500, home_type: \"condos\", bedrooms: \"studios\", bathrooms: \"any\" }\n",
      "Failed to decode JSON from LLM response. Response text:\n",
      "{ city: \"Los Angeles, CA\", min_price: 1500, home_type: \"condos\", bedrooms: \"studios\", bathrooms: \"any\" }\n",
      "Generated URL: https://www.apartments.com/apartments/los-angeles-ca/min-2-bedrooms-1-bathrooms-over-1500/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/52k791n10qj37p5d0t3151w80000gn/T/ipykernel_72387/2442583574.py:162: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return generate_apartments_url(parsed_params.dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA Answer: I recommend the condo listing at:\n",
      "\n",
      "**755 S Spring St, Los Angeles, CA 90014**\n",
      "\n",
      "This studio condominium (Unit Type: 1) is a great match for your search criteria. The building offers various amenities, including:\n",
      "\n",
      "- In Unit Washer & Dryer\n",
      "- Dishwasher\n",
      "- Kitchen with refrigerator\n",
      "\n",
      "Additional details include:\n",
      "\n",
      "- Pets Allowed\n",
      "- Specials available\n",
      "\n",
      "You can reach the property manager at (747) 307-6352 or via email to inquire about this unit.\n",
      "\n",
      "Please note that there are two other listings ($3,100 - $3,200 and $8,950), but they have different amenities and prices, which may not align with your search criteria. This studio condo at 755 S Spring St appears to be the most suitable option based on the provided information.\n"
     ]
    }
   ],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import urllib.parse\n",
    "import json\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph  # For potential future extension.\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Environment & Global Setup\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "root_dir = Path().resolve()\n",
    "print(root_dir.parent / '.env')\n",
    "\n",
    "config = Config(RepositoryEnv(root_dir.parent / '.env'))  # Explicitly load .env\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config('LANGSMITH_API_KEY')\n",
    "\n",
    "# Initialize two LLM instances:\n",
    "# 1. For URL generation.\n",
    "llm_url = ChatOllama(model=\"llama3.2\")\n",
    "# 2. For downstream QA.\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LLM-based URL Generation Chain\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class ApartmentQuery(BaseModel):\n",
    "    city: str = Field(\n",
    "        description=\"City with state abbreviation, e.g., 'Los Angeles, CA'\"\n",
    "    )\n",
    "    min_price: int = Field(\n",
    "        description=\"Minimum price as an integer, e.g., 1500\"\n",
    "    )\n",
    "    home_type: str = Field(\n",
    "        default=\"apartments\",\n",
    "        description=\"Home type: one of apartments, houses, condos, townhomes. Defaults to apartments.\"\n",
    "    )\n",
    "    bedrooms: str = Field(\n",
    "        default=\"2+\",\n",
    "        description=\"Bedroom filter: one of any, studio, 1+, 2+, 3+, 4+. For a studio, output 'studios'. Defaults to 2+.\"\n",
    "    )\n",
    "    bathrooms: str = Field(\n",
    "        default=\"1+\",\n",
    "        description=\"Bathroom filter: one of any, 1+, 2+, 3+. Defaults to 1+.\"\n",
    "    )\n",
    "\n",
    "# Set up the output parser.\n",
    "parser = PydanticOutputParser(pydantic_object=ApartmentQuery)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a data extraction assistant. Extract the following details from the user's query:\n",
    "- city: The city with its state abbreviation (e.g., \"Los Angeles, CA\").\n",
    "- min_price: The minimum price as an integer (e.g., 1500).\n",
    "- home_type: One of: apartments, houses, condos, townhomes. (Default: apartments)\n",
    "- bedrooms: One of: any, studio, 1+, 2+, 3+, 4+ (Default: 2+). For a studio, output \"studios\".\n",
    "- bathrooms: One of: any, 1+, 2+, 3+ (Default: 1+).\n",
    "\n",
    "Return your answer as a JSON object with exactly these keys: \"city\", \"min_price\", \"home_type\", \"bedrooms\", \"bathrooms\".\n",
    "Query: \"{query}\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def generate_apartments_url(params: dict) -> str:\n",
    "    city_slug = re.sub(r'[,\\s]+', '-', params[\"city\"].lower().strip())\n",
    "    home_type_lower = params[\"home_type\"].lower().strip()\n",
    "    if home_type_lower not in [\"apartments\", \"houses\", \"condos\", \"townhomes\"]:\n",
    "        home_type_lower = \"apartments\"\n",
    "    bed_map = {\n",
    "        \"any\": \"\",\n",
    "        \"studio\": \"studios\",\n",
    "        \"1+\": \"min-1-bedrooms\",\n",
    "        \"2+\": \"min-2-bedrooms\",\n",
    "        \"3+\": \"min-3-bedrooms\",\n",
    "        \"4+\": \"min-4-bedrooms\"\n",
    "    }\n",
    "    bedroom_seg = bed_map.get(params[\"bedrooms\"].lower().strip(), \"min-2-bedrooms\")\n",
    "    bath_map = {\n",
    "        \"any\": \"\",\n",
    "        \"1+\": \"1-bathrooms\",\n",
    "        \"2+\": \"2-bathrooms\",\n",
    "        \"3+\": \"3-bathrooms\"\n",
    "    }\n",
    "    bathroom_seg = bath_map.get(params[\"bathrooms\"].lower().strip(), \"1-bathrooms\")\n",
    "    price_segment = f\"over-{params['min_price']}\"\n",
    "    segments = []\n",
    "    if bedroom_seg:\n",
    "        segments.append(bedroom_seg)\n",
    "    if bathroom_seg:\n",
    "        segments.append(bathroom_seg)\n",
    "    segments.append(price_segment)\n",
    "    middle_segment = \"-\".join(segments)\n",
    "    return f\"https://www.apartments.com/{home_type_lower}/{city_slug}/{middle_segment}/\"\n",
    "\n",
    "def parse_json_with_stripped_keys(text: str) -> dict:\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON from LLM response. Response text:\")\n",
    "        print(text)\n",
    "        raise e\n",
    "    return {k.strip(): v for k, v in data.items()}\n",
    "\n",
    "def build_search_url(query: str) -> str:\n",
    "    formatted_prompt = prompt.format(\n",
    "        query=query,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    llm_response = llm_url.invoke(formatted_prompt)\n",
    "    response_text = llm_response.content if hasattr(llm_response, \"content\") else str(llm_response)\n",
    "    \n",
    "    # If the response is empty, log and use default parameters\n",
    "    if not response_text.strip():\n",
    "        print(\"LLM response is empty. Using default parameters.\")\n",
    "        default_data = {\n",
    "            \"city\": \"Los Angeles, CA\",\n",
    "            \"min_price\": 1500,\n",
    "            \"home_type\": \"apartments\",\n",
    "            \"bedrooms\": \"2+\",\n",
    "            \"bathrooms\": \"1+\"\n",
    "        }\n",
    "        parsed_params = ApartmentQuery(**default_data)\n",
    "        return generate_apartments_url(parsed_params.dict())\n",
    "    \n",
    "    # Try to parse the JSON response\n",
    "    try:\n",
    "        fixed_data = parse_json_with_stripped_keys(response_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON from LLM response. Response text:\")\n",
    "        print(response_text)\n",
    "        # Use fallback default parameters if JSON parsing fails.\n",
    "        default_data = {\n",
    "            \"city\": \"Los Angeles, CA\",\n",
    "            \"min_price\": 1500,\n",
    "            \"home_type\": \"apartments\",\n",
    "            \"bedrooms\": \"2+\",\n",
    "            \"bathrooms\": \"1+\"\n",
    "        }\n",
    "        parsed_params = ApartmentQuery(**default_data)\n",
    "        return generate_apartments_url(parsed_params.dict())\n",
    "    \n",
    "    parsed_params = ApartmentQuery(**fixed_data)\n",
    "    return generate_apartments_url(parsed_params.dict())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Custom Web Loader\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    def load(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\",\n",
    "            id=\"placardContainer\",\n",
    "            class_=\"placardContainer\",\n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        content = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section)\\\n",
    "            .get_text(separator=\"\\n\", strip=True)\n",
    "        return [Document(page_content=content, metadata={\"source\": self.web_path})]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Downstream Processing: Indexing & QA Pipeline\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "user_query = \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\"\n",
    "target_url = build_search_url(user_query)\n",
    "print(\"Generated URL:\", target_url)\n",
    "\n",
    "loader = CustomWebLoader(target_url)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Updated generate function with strict instructions to avoid hallucinations.\n",
    "def generate(state: dict) -> dict:\n",
    "    # Combine all retrieved document contents.\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a highly confident, precise real estate recommendation engine. \"\n",
    "                \"Based solely on the provided crawled context, you must select one specific condo listing that best meets the search criteria. \"\n",
    "                \"Even if some details are missing, combine the available information to provide a clear, detailed recommendation. \"\n",
    "                \"Do NOT state that you cannot recommend or express uncertainty. \"\n",
    "                \"Always output a recommendation that includes the exact address, unit type, and amenities as they appear in the context. \"\n",
    "                \"If a particular detail is not mentioned, simply omit it—do not add or hallucinate any information.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Below is the crawled context from apartments.com:\\n\\n\"\n",
    "                f\"{docs_content}\\n\\n\"\n",
    "                \"Based solely on this data, please provide a detailed recommendation for one specific condo listing that meets the search criteria. \"\n",
    "                \"Include all available details (e.g. address, unit type, and amenities) exactly as found in the context.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    state[\"answer\"] = response.content\n",
    "    return state\n",
    "\n",
    "\n",
    "def retrieve(state: dict) -> dict:\n",
    "    state[\"context\"] = vector_store.similarity_search(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def run_pipeline(state: State) -> State:\n",
    "    state = retrieve(state)\n",
    "    state = generate(state)\n",
    "    return state\n",
    "\n",
    "initial_state: State = {\"question\": user_query, \"context\": [], \"answer\": \"\"}\n",
    "result_state = run_pipeline(initial_state)\n",
    "print(\"QA Answer:\", result_state[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740003fd-8629-4e02-8a46-97528a8a9521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
