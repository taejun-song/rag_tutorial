{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3bba8a-0a5c-4a76-af35-7b5c0635f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"I want condos in Los Angeles, CA with studio options, priced over 1500, and any bathrooms.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0d55b-6ded-48e7-a29c-9039b5f7d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taejunsong/workspace/rag_tutorial/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/52k791n10qj37p5d0t3151w80000gn/T/ipykernel_90635/908103340.py:165: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return generate_apartments_url(parsed_params.dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated URL: https://www.apartments.com/condos/los-angeles-ca/min-2-bedrooms-over-1500/\n"
     ]
    }
   ],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import urllib.parse\n",
    "import json\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph  # For potential future extension.\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Environment & Global Setup\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "root_dir = Path().resolve()\n",
    "print(root_dir.parent / '.env')\n",
    "\n",
    "config = Config(RepositoryEnv(root_dir.parent / '.env'))  # Explicitly load .env\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config('LANGSMITH_API_KEY')\n",
    "\n",
    "# Initialize two LLM instances:\n",
    "# 1. For URL generation.\n",
    "llm_url = ChatOllama(model=\"llama3.2\")\n",
    "# 2. For downstream QA.\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LLM-based URL Generation Chain\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class ApartmentQuery(BaseModel):\n",
    "    city: str = Field(\n",
    "        description=\"City with state abbreviation, e.g., 'Los Angeles, CA'\"\n",
    "    )\n",
    "    min_price: int = Field(\n",
    "        description=\"Minimum price as an integer, e.g., 1500\"\n",
    "    )\n",
    "    home_type: str = Field(\n",
    "        default=\"apartments\",\n",
    "        description=\"Home type: one of apartments, houses, condos, townhomes. Defaults to apartments.\"\n",
    "    )\n",
    "    bedrooms: str = Field(\n",
    "        default=\"2+\",\n",
    "        description=\"Bedroom filter: one of any, studio, 1+, 2+, 3+, 4+. For a studio, output 'studios'. Defaults to 2+.\"\n",
    "    )\n",
    "    bathrooms: str = Field(\n",
    "        default=\"1+\",\n",
    "        description=\"Bathroom filter: one of any, 1+, 2+, 3+. Defaults to 1+.\"\n",
    "    )\n",
    "\n",
    "# Set up the output parser.\n",
    "parser = PydanticOutputParser(pydantic_object=ApartmentQuery)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a data extraction assistant. Extract the following details from the user's query:\n",
    "- city: The city with its state abbreviation (e.g., \"Los Angeles, CA\").\n",
    "- min_price: The minimum price as an integer (e.g., 1500).\n",
    "- home_type: One of: apartments, houses, condos, townhomes. (Default: apartments)\n",
    "- bedrooms: One of: any, studio, 1+, 2+, 3+, 4+ (Default: 2+). For a studio, output \"studios\".\n",
    "- bathrooms: One of: any, 1+, 2+, 3+ (Default: 1+).\n",
    "\n",
    "Return your answer as a JSON object with exactly these keys: \"city\", \"min_price\", \"home_type\", \"bedrooms\", \"bathrooms\".\n",
    "Query: \"{query}\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def generate_apartments_url(params: dict) -> str:\n",
    "    city_slug = re.sub(r'[,\\s]+', '-', params[\"city\"].lower().strip())\n",
    "    home_type_lower = params[\"home_type\"].lower().strip()\n",
    "    if home_type_lower not in [\"apartments\", \"houses\", \"condos\", \"townhomes\"]:\n",
    "        home_type_lower = \"apartments\"\n",
    "    bed_map = {\n",
    "        \"any\": \"\",\n",
    "        \"studio\": \"studios\",\n",
    "        \"1+\": \"min-1-bedrooms\",\n",
    "        \"2+\": \"min-2-bedrooms\",\n",
    "        \"3+\": \"min-3-bedrooms\",\n",
    "        \"4+\": \"min-4-bedrooms\"\n",
    "    }\n",
    "    bedroom_seg = bed_map.get(params[\"bedrooms\"].lower().strip(), \"min-2-bedrooms\")\n",
    "    bath_map = {\n",
    "        \"any\": \"\",\n",
    "        \"1+\": \"1-bathrooms\",\n",
    "        \"2+\": \"2-bathrooms\",\n",
    "        \"3+\": \"3-bathrooms\"\n",
    "    }\n",
    "    bathroom_seg = bath_map.get(params[\"bathrooms\"].lower().strip(), \"1-bathrooms\")\n",
    "    price_segment = f\"over-{params['min_price']}\"\n",
    "    segments = []\n",
    "    if bedroom_seg:\n",
    "        segments.append(bedroom_seg)\n",
    "    if bathroom_seg:\n",
    "        segments.append(bathroom_seg)\n",
    "    segments.append(price_segment)\n",
    "    middle_segment = \"-\".join(segments)\n",
    "    return f\"https://www.apartments.com/{home_type_lower}/{city_slug}/{middle_segment}/\"\n",
    "\n",
    "def parse_json_with_stripped_keys(text: str) -> dict:\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON from LLM response. Response text:\")\n",
    "        print(text)\n",
    "        raise e\n",
    "    return {k.strip(): v for k, v in data.items()}\n",
    "\n",
    "def build_search_url(query: str) -> str:\n",
    "    formatted_prompt = prompt.format(\n",
    "        query=query,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    llm_response = llm_url.invoke(formatted_prompt)\n",
    "    response_text = llm_response.content if hasattr(llm_response, \"content\") else str(llm_response)\n",
    "    \n",
    "    # If the response is empty, log and use default parameters\n",
    "    if not response_text.strip():\n",
    "        print(\"LLM response is empty. Using default parameters.\")\n",
    "        default_data = {\n",
    "            \"city\": \"Los Angeles, CA\",\n",
    "            \"min_price\": 1500,\n",
    "            \"home_type\": \"apartments\",\n",
    "            \"bedrooms\": \"2+\",\n",
    "            \"bathrooms\": \"1+\"\n",
    "        }\n",
    "        parsed_params = ApartmentQuery(**default_data)\n",
    "        return generate_apartments_url(parsed_params.dict())\n",
    "    \n",
    "    # Try to parse the JSON response\n",
    "    try:\n",
    "        fixed_data = parse_json_with_stripped_keys(response_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON from LLM response. Response text:\")\n",
    "        print(response_text)\n",
    "        # Use fallback default parameters if JSON parsing fails.\n",
    "        default_data = {\n",
    "            \"city\": \"Los Angeles, CA\",\n",
    "            \"min_price\": 1500,\n",
    "            \"home_type\": \"apartments\",\n",
    "            \"bedrooms\": \"2+\",\n",
    "            \"bathrooms\": \"1+\"\n",
    "        }\n",
    "        parsed_params = ApartmentQuery(**default_data)\n",
    "        return generate_apartments_url(parsed_params.dict())\n",
    "    \n",
    "    parsed_params = ApartmentQuery(**fixed_data)\n",
    "    return generate_apartments_url(parsed_params.dict())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Custom Web Loader\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "    def load(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        try:\n",
    "            response = session.get(self.web_path, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error fetching the page:\", e)\n",
    "            return []\n",
    "        filter_section = SoupStrainer(\n",
    "            \"div\",\n",
    "            id=\"placardContainer\",\n",
    "            class_=\"placardContainer\",\n",
    "            attrs={\"data-analytics-profiletype\": \"Unknown\"}\n",
    "        )\n",
    "        content = BeautifulSoup(response.text, \"html.parser\", parse_only=filter_section)\\\n",
    "            .get_text(separator=\"\\n\", strip=True)\n",
    "        return [Document(page_content=content, metadata={\"source\": self.web_path})]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Downstream Processing: Indexing & QA Pipeline\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "target_url = build_search_url(user_query)\n",
    "print(\"Generated URL:\", target_url)\n",
    "\n",
    "loader = CustomWebLoader(target_url)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Updated generate function with strict instructions to avoid hallucinations.\n",
    "def generate(state: dict) -> dict:\n",
    "    # Combine all retrieved document contents.\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a highly confident, precise real estate recommendation engine. \"\n",
    "                \"Based solely on the provided crawled context, you must select one specific condo listing that best meets the search criteria. \"\n",
    "                \"Even if some details are missing, combine the available information to provide a clear, detailed recommendation. \"\n",
    "                \"Do NOT state that you cannot recommend or express uncertainty. \"\n",
    "                \"Always output a recommendation that includes the exact address, unit type, and amenities as they appear in the context. \"\n",
    "                \"If a particular detail is not mentioned, simply omit itâ€”do not add or hallucinate any information.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Below is the crawled context from apartments.com:\\n\\n\"\n",
    "                f\"{docs_content}\\n\\n\"\n",
    "                \"Based solely on this data, please provide a detailed recommendation for one specific condo listing that meets the search criteria. \"\n",
    "                \"Include all available details (e.g. address, unit type, and amenities) exactly as found in the context.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    state[\"answer\"] = response.content\n",
    "    return state\n",
    "\n",
    "\n",
    "def retrieve(state: dict) -> dict:\n",
    "    state[\"context\"] = vector_store.similarity_search(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def run_pipeline(state: State) -> State:\n",
    "    state = retrieve(state)\n",
    "    state = generate(state)\n",
    "    return state\n",
    "\n",
    "initial_state: State = {\"question\": user_query, \"context\": [], \"answer\": \"\"}\n",
    "result_state = run_pipeline(initial_state)\n",
    "print(\"QA Answer:\", result_state[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740003fd-8629-4e02-8a46-97528a8a9521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
